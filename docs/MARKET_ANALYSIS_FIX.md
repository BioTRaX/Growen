# An√°lisis y Correcci√≥n: Flujo de Estudio de Mercado

**Fecha**: 2025-11-16  
**Estado**: Parcialmente funcional (c√°lculo OK, scraping NO)

---

## üîç Estado Actual del Sistema

### ‚úÖ **Componentes Funcionando**

#### 1. **Base de Datos PostgreSQL**
- **Contenedor**: `growen-postgres` (NO `growen-db-1`)
- **Puerto**: `5433:5432`
- **Estado**: Healthy, conectado correctamente
- **Tabla**: `market_sources` con campos:
  - `product_id`: FK a canonical_products
  - `source_name`: Nombre de la tienda
  - `url`: URL de la fuente
  - `last_price`: √öltimo precio obtenido (Decimal)
  - `last_checked_at`: Timestamp de √∫ltima actualizaci√≥n
  - `is_mandatory`: Boolean para fuentes obligatorias

#### 2. **API Backend (C√°lculo de Rango)** ‚úÖ
- **Endpoint 1**: `GET /market/products`
  - ‚úÖ Calcula `market_price_min` y `market_price_max` consultando `market_sources`
  - ‚úÖ Query por producto:
    ```python
    query_prices = (
        select(MarketSource.last_price)
        .where(
            and_(
                MarketSource.product_id == prod.id,
                MarketSource.last_price.isnot(None)
            )
        )
    )
    ```
  - ‚úÖ Retorna `min(prices)` y `max(prices)`

- **Endpoint 2**: `GET /market/products/{id}/sources`
  - ‚úÖ Schema actualizado con `market_price_min` y `market_price_max`
  - ‚úÖ Calcula rango iterando sobre fuentes cargadas
  - ‚úÖ Solo considera precios v√°lidos (`last_price IS NOT NULL`)

#### 3. **Frontend UI** ‚úÖ
- **Componente**: `MarketDetailModal.tsx`
- ‚úÖ Muestra "Rango de Mercado: $ min - $ max"
- ‚úÖ Actualiza autom√°ticamente cuando hay datos
- ‚úÖ Muestra "Sin datos" cuando no hay precios

#### 4. **Redis** ‚úÖ
- **Contenedor**: `growen-redis` (NO `redis-1`)
- **Puerto**: `6379:6379`
- **Estado**: Running
- **Prop√≥sito**: Cola de tareas para Dramatiq

#### 5. **Servicios MCP** ‚úÖ
- `growen-mcp-products` - Puerto 8100
- `growen-mcp-web-search` - Puerto 8102
- Ambos healthy y funcionando

---

### ‚ùå **Componentes NO Funcionando**

#### 1. **Worker de Market Scraping** üî¥
- **PID**: 15616 (proceso zombie)
- **Error cr√≠tico**: `Error 10061 connecting to localhost:6379`
- **Causa**: 
  - Worker inici√≥ ANTES de que Redis estuviera disponible
  - Intenta conectar a `localhost` en lugar de `127.0.0.1`
  - Loop infinito de reconexi√≥n cada 3 segundos

**Evidencia en logs**:
```
[2025-11-16 13:53:59,189] [dramatiq.worker.ConsumerThread(market)] [CRITICAL] 
Consumer encountered a connection error: Error 10061 connecting to localhost:6379
[INFO] Restarting consumer in 3.00 seconds.
```

**Impacto**:
- ‚ùå No se procesan tareas encoladas de actualizaci√≥n de precios
- ‚ùå Bot√≥n "üîÑ Actualizar Precios" encola tarea (202 Accepted) pero nunca se ejecuta
- ‚ùå Los precios nunca se actualizan autom√°ticamente v√≠a scraping

---

## üîÑ Flujo Actual de Estudio de Mercado

### **Flujo Completo (Dise√±ado)**

```
Usuario ‚Üí UI ‚Üí API ‚Üí Redis ‚Üí Worker ‚Üí Scraping ‚Üí DB ‚Üí API ‚Üí UI
   ‚îÇ       ‚îÇ     ‚îÇ      ‚îÇ       ‚îÇ         ‚îÇ        ‚îÇ     ‚îÇ     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ùå ROTO AQU√ç
```

### **Paso a Paso Detallado**

#### **Fase 1: Configuraci√≥n de Fuentes** ‚úÖ
1. Usuario abre modal de producto (`MarketDetailModal`)
2. Click en "+ Agregar Fuente" o "Buscar fuentes autom√°ticamente"
3. **Opci√≥n A - Manual**:
   - `POST /market/products/{id}/sources`
   - Body: `{ source_name, url, is_mandatory }`
   - Inserta en `market_sources` con `last_price=null`
4. **Opci√≥n B - Descubrimiento Autom√°tico**:
   - `POST /market/products/{id}/discover-sources?max_results=20`
   - Llama MCP Web Search (DuckDuckGo)
   - Filtra resultados por dominio conocido
   - Retorna URLs sugeridas
   - Usuario selecciona y agrega

**Estado actual**: ‚úÖ Funciona perfectamente

---

#### **Fase 2: Actualizaci√≥n de Precios** ‚ùå ROTO

**Flujo Dise√±ado**:
```
1. Usuario ‚Üí Click "üîÑ Actualizar Precios"
2. UI ‚Üí POST /market/products/{id}/refresh-market
3. API ‚Üí Valida producto existe
4. API ‚Üí refresh_market_prices_task.send(product_id)
5. API ‚Üí Retorna 202 Accepted con job_id
6. Redis ‚Üí Encola mensaje en cola "market"
7. Worker ‚Üí Consume mensaje de Redis
8. Worker ‚Üí Ejecuta scraping para cada fuente del producto
9. Worker ‚Üí Actualiza market_sources.last_price y last_checked_at
10. Worker ‚Üí Actualiza canonical_products.market_price_updated_at
11. Usuario ‚Üí Recarga modal despu√©s de 3 segundos
12. API ‚Üí Calcula rango desde market_sources
13. UI ‚Üí Muestra "$ min - $ max"
```

**Flujo Actual (Roto en paso 7)**:
```
1. Usuario ‚Üí Click "üîÑ Actualizar Precios" ‚úÖ
2. UI ‚Üí POST /market/products/{id}/refresh-market ‚úÖ
3. API ‚Üí Valida producto existe ‚úÖ
4. API ‚Üí refresh_market_prices_task.send(product_id) ‚úÖ
5. API ‚Üí Retorna 202 Accepted ‚úÖ
6. Redis ‚Üí Mensaje encolado en "market" ‚úÖ
7. Worker ‚Üí ‚ùå NO CONSUME (sin conexi√≥n a Redis)
8. Worker ‚Üí ‚ùå NUNCA EJECUTA
9-13. ‚Üí ‚ùå NUNCA OCURREN
```

**Resultado**:
- Tarea queda en Redis indefinidamente
- Precios nunca se actualizan
- UI muestra "Sin datos" en rango

---

#### **Fase 3: C√°lculo y Visualizaci√≥n** ‚úÖ

**Cuando HAY precios** (insertados manualmente o scrapeados):
```
1. GET /market/products/{id}/sources
2. Query: SELECT last_price FROM market_sources WHERE product_id = {id} AND last_price IS NOT NULL
3. Calcula: min(prices), max(prices)
4. Retorna: { market_price_min: 1180.0, market_price_max: 1350.0 }
5. UI muestra: "$ 1,180.00 - $ 1,350.00"
```

**Estado actual**: ‚úÖ Funciona correctamente (probado con datos manuales)

---

## üõ†Ô∏è Diagn√≥stico del Problema del Worker

### **Causa Ra√≠z**
El worker inici√≥ antes que Redis, intent√≥ conectar, fall√≥, y qued√≥ en loop infinito de reconexi√≥n.

### **Por qu√© localhost vs 127.0.0.1 falla**
- Windows resuelve `localhost` a `::1` (IPv6) primero
- Redis en Docker solo escucha en `0.0.0.0` y `127.0.0.1` (IPv4)
- La conexi√≥n falla con "Connection refused"

### **Evidencia en netstat**
```powershell
TCP    0.0.0.0:6379           0.0.0.0:0              LISTENING       22992  # Redis escucha en IPv4
TCP    [::]:6379              [::]:0                 LISTENING       22992  # Redis escucha en IPv6
```

Pero el worker intenta `localhost:6379` que puede resolver a IPv6 primero.

---

## ‚úÖ Soluciones Implementadas

### **1. Correcci√≥n del C√°lculo de Rango** ‚úÖ COMPLETO

**Archivo**: `services/routers/market.py`

**Cambio 1 - Endpoint `/market/products`** (l√≠neas ~206-240):
```python
# ANTES:
# TODO Etapa 2: Calcular market_price_min, market_price_max desde market_sources
market_price_min_val = None
market_price_max_val = None

# DESPU√âS:
# Calcular market_price_min, market_price_max desde market_sources
market_price_min_val = None
market_price_max_val = None

query_prices = (
    select(MarketSource.last_price)
    .where(
        and_(
            MarketSource.product_id == prod.id,
            MarketSource.last_price.isnot(None)
        )
    )
)
result_prices = await db.execute(query_prices)
prices = [float(p) for p in result_prices.scalars().all() if p is not None]

if prices:
    market_price_min_val = min(prices)
    market_price_max_val = max(prices)
```

**Cambio 2 - Schema `ProductSourcesResponse`** (l√≠neas ~275-284):
```python
class ProductSourcesResponse(BaseModel):
    product_id: int
    product_name: str
    sale_price: Optional[float] = None
    market_price_reference: Optional[float] = None
    market_price_updated_at: Optional[str] = ...
    market_price_min: Optional[float] = Field(None, description="Precio m√≠nimo calculado desde fuentes")  # ‚úÖ NUEVO
    market_price_max: Optional[float] = Field(None, description="Precio m√°ximo calculado desde fuentes")  # ‚úÖ NUEVO
    mandatory: list[MarketSourceItem] = ...
    additional: list[MarketSourceItem] = ...
```

**Cambio 3 - Endpoint `/products/{id}/sources`** (l√≠neas ~332-368):
```python
# Separar fuentes y calcular rango
mandatory_sources = []
additional_sources = []
prices = []  # ‚úÖ NUEVO

for source in sources:
    item = MarketSourceItem(...)
    
    # ‚úÖ NUEVO: Recopilar precios v√°lidos
    if source.last_price is not None:
        prices.append(float(source.last_price))
    
    if source.is_mandatory:
        mandatory_sources.append(item)
    else:
        additional_sources.append(item)

# ‚úÖ NUEVO: Calcular rango
market_price_min_val = min(prices) if prices else None
market_price_max_val = max(prices) if prices else None

return ProductSourcesResponse(
    ...,
    market_price_min=market_price_min_val,  # ‚úÖ NUEVO
    market_price_max=market_price_max_val,  # ‚úÖ NUEVO
    ...
)
```

**Resultado**: ‚úÖ Rango se calcula correctamente cuando hay precios

---

### **2. Datos de Prueba para Validaci√≥n** ‚úÖ COMPLETO

**Comando ejecutado**:
```sql
UPDATE market_sources SET last_price = 1180.00, last_checked_at = NOW() WHERE id = 1;
UPDATE market_sources SET last_price = 1350.00, last_checked_at = NOW() WHERE id = 2;
```

**Resultado**:
```
Producto 45 - "Bandeja Bulldog Lisa"
‚îú‚îÄ‚îÄ Fuente 1: ML Bandeja Bulldog 27*18 ‚Üí $ 1,180.00
‚îî‚îÄ‚îÄ Fuente 2: 0800 Grow ‚Üí $ 1,350.00

Rango calculado: $ 1,180.00 - $ 1,350.00 ‚úÖ
```

---

## üöÄ Soluciones Pendientes

### **Soluci√≥n 1: Reparar Worker de Market** üî¥ URGENTE

#### **Opci√≥n A - Reinicio Limpio del Worker** (Recomendado)
```powershell
# 1. Detener worker zombie desde el panel de admin
#    O terminar proceso manualmente:
taskkill /PID 15616 /F

# 2. Limpiar logs antiguos
Remove-Item "logs\worker_market.log" -Force

# 3. Verificar Redis est√° corriendo
docker ps | Select-String "growen-redis"

# 4. Reiniciar worker desde admin panel
#    O manualmente:
.\scripts\start_worker_market.cmd
```

**Validaci√≥n post-reinicio**:
```powershell
# Verificar conexi√≥n exitosa a Redis
Get-Content "logs\worker_market.log" -Tail 20 | Select-String "connected|ready|listening"

# Debe mostrar:
# [INFO] Consumer is ready.
# [INFO] Connected to Redis at 127.0.0.1:6379
```

---

#### **Opci√≥n B - Forzar IP 127.0.0.1 en .env** (Si Opci√≥n A falla)

**Archivo**: `.env`
```bash
# CAMBIAR:
REDIS_URL=redis://localhost:6379/0

# A:
REDIS_URL=redis://127.0.0.1:6379/0
```

Luego reiniciar worker.

---

#### **Opci√≥n C - Modo Inline (Sin Redis)** (Solo desarrollo, NO producci√≥n)

**Archivo**: `.env`
```bash
RUN_INLINE_JOBS=1
```

**NOTA**: Esto ejecuta tareas s√≠ncronamente, bloqueando la API. Solo para debug.

---

### **Soluci√≥n 2: Mejorar Configuraci√≥n del Worker** üìã

**Archivo**: `scripts/start_worker_market.cmd`

**Agregar validaci√≥n de Redis antes de iniciar**:
```batch
@echo off
echo [INFO] Verificando conexi√≥n a Redis...

REM Probar conexi√≥n a Redis
python -c "import redis; r = redis.Redis(host='127.0.0.1', port=6379); r.ping(); print('[OK] Redis disponible')" 2>nul
if errorlevel 1 (
    echo [ERROR] Redis no disponible en 127.0.0.1:6379
    echo [ERROR] Ejecuta: docker ps ^| findstr redis
    pause
    exit /b 1
)

echo [INFO] Iniciando worker de market...
python -m dramatiq workers.market_scraping --processes 1 --threads 4 --watch . >> logs\worker_market.log 2>&1
```

---

### **Soluci√≥n 3: Implementar Scraping Real** üìã

**Archivo actual**: `workers/market_scraping.py`

**Estado de implementaci√≥n**:
- ‚úÖ Task `refresh_market_prices_task` implementada con Dramatiq
- ‚úÖ Funci√≥n `scrape_market_source()` soporta:
  - Scraping est√°tico con `requests + BeautifulSoup`
  - Scraping din√°mico con `Playwright`
- ‚úÖ Manejo robusto de errores (NetworkError, PriceNotFoundError)
- ‚úÖ Logging detallado con contexto
- ‚úÖ Fix para Windows `ProactorEventLoop` incompatible con psycopg async

**Flujo del worker**:
1. Recibe `product_id` de la cola Redis
2. Consulta todas las fuentes del producto (`market_sources`)
3. Itera sobre cada fuente:
   - Determina tipo (`static` vs `dynamic`)
   - Ejecuta scraping con timeout de 15 segundos
   - Extrae precio y moneda
   - Actualiza `last_price` y `last_checked_at` en DB
4. Actualiza `market_price_updated_at` en producto can√≥nico
5. Retorna resumen con fuentes exitosas/fallidas

**Ejemplo de log esperado** (cuando funcione):
```
[INFO] Iniciando scraping para producto 'Bandeja Bulldog Lisa' - fuente 'ML Bandeja Bulldog 27*18'
[INFO] ‚úì Precio extra√≠do exitosamente: 1180.00 ARS
[INFO] Guardando precio en DB para fuente ID 1
[INFO] Scraping completado para producto 45: 2/2 fuentes exitosas
```

**Estado actual**:
- ‚ùå Worker no conecta a Redis ‚Üí nunca procesa tareas
- ‚úÖ L√≥gica de scraping lista para usar
- ‚úÖ Parsers de HTML funcionan correctamente

---

## üìä Evoluciones Propuestas

### **Nivel 1: Reparaci√≥n Inmediata** (1-2 horas)

#### **1.1 Arreglar Worker** üî¥ CR√çTICO
- [ ] Detener proceso zombie (PID 15616)
- [ ] Cambiar `.env`: `REDIS_URL=redis://127.0.0.1:6379/0`
- [ ] Reiniciar worker desde admin panel
- [ ] Validar conexi√≥n exitosa a Redis
- [ ] Probar actualizaci√≥n de precios en UI

#### **1.2 Documentar Nombres Correctos de Contenedores** üìù
- [x] `growen-postgres` (NO `growen-db-1`)
- [x] `growen-redis` (NO `redis-1`)
- [ ] Actualizar README.md con nombres reales
- [ ] Actualizar scripts que usan nombres antiguos

---

### **Nivel 2: Mejoras de Estabilidad** (1 semana)

#### **2.1 Health Checks del Worker**
**Archivo nuevo**: `services/routers/worker_health.py`

```python
@router.get("/health/worker/market")
async def worker_market_health():
    """
    Verifica si el worker de market est√° procesando tareas.
    Retorna √∫ltimo job procesado y tiempo desde √∫ltima ejecuci√≥n.
    """
    # Query a Redis para ver tareas pendientes
    # Query a DB para ver √∫ltima actualizaci√≥n de precios
    # Retorna: { status: "healthy|degraded|down", last_run: ..., pending_jobs: ... }
```

**Uso**: Panel de admin muestra indicador visual del estado del worker.

---

#### **2.2 Retry Logic Inteligente**
**Archivo**: `workers/market_scraping.py`

**Mejora**:
```python
@dramatiq.actor(
    max_retries=3,
    min_backoff=60000,  # 1 minuto
    max_backoff=3600000,  # 1 hora
    queue_name="market"
)
def refresh_market_prices_task(product_id: int):
    # Si falla por timeout, reintenta en 1 min
    # Si falla por bloqueo (429), reintenta en 1 hora
    # Si falla por precio no encontrado, no reintenta
```

---

#### **2.3 Cache de Resultados**
**Objetivo**: Evitar scrapear la misma URL m√∫ltiples veces en corto tiempo.

**Tabla nueva**: `market_scraping_cache`
```sql
CREATE TABLE market_scraping_cache (
    url_hash VARCHAR(64) PRIMARY KEY,  -- SHA256(url)
    last_price DECIMAL(12,2),
    currency VARCHAR(10),
    cached_at TIMESTAMP,
    expires_at TIMESTAMP,
    hit_count INTEGER DEFAULT 1
);
```

**L√≥gica**:
- Si URL scrapeada hace <1 hora, usar cache
- Si URL cambi√≥, invalidar cache
- Contador de hits para m√©tricas

---

### **Nivel 3: Funcionalidades Avanzadas** (1 mes)

#### **3.1 Scraping Programado (Cron Jobs)**
**Objetivo**: Actualizar precios autom√°ticamente sin intervenci√≥n manual.

**Implementaci√≥n**:
- Usar `APScheduler` o Dramatiq Middleware
- Configurar frecuencias por categor√≠a:
  - Productos premium: cada 6 horas
  - Productos est√°ndar: cada 24 horas
  - Productos de baja rotaci√≥n: cada 7 d√≠as

**Archivo nuevo**: `services/jobs/market_scheduler.py`
```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

@scheduler.scheduled_job('cron', hour='*/6')
async def update_premium_products():
    products = await get_products_by_category("premium")
    for product in products:
        refresh_market_prices_task.send(product.id)
```

---

#### **3.2 Detecci√≥n de Anomal√≠as de Precio**
**Objetivo**: Alertar cuando un precio se desv√≠a significativamente del rango hist√≥rico.

**Tabla nueva**: `market_price_history`
```sql
CREATE TABLE market_price_history (
    id SERIAL PRIMARY KEY,
    source_id INTEGER REFERENCES market_sources(id),
    price DECIMAL(12,2),
    currency VARCHAR(10),
    scraped_at TIMESTAMP DEFAULT NOW(),
    INDEX idx_source_scraped (source_id, scraped_at DESC)
);
```

**L√≥gica**:
```python
def detect_price_anomaly(source_id: int, new_price: Decimal) -> bool:
    # Obtener √∫ltimos 10 precios
    history = get_price_history(source_id, limit=10)
    avg = mean(history)
    stddev = stdev(history)
    
    # Precio fuera de ¬±2 desviaciones est√°ndar
    if abs(new_price - avg) > 2 * stddev:
        create_alert(
            type="price_anomaly",
            source_id=source_id,
            message=f"Precio {new_price} fuera de rango esperado {avg}¬±{2*stddev}"
        )
        return True
    return False
```

---

#### **3.3 Integraci√≥n con APIs de Mercado Libre**
**Objetivo**: Usar API oficial en lugar de scraping para ML.

**Ventajas**:
- ‚úÖ M√°s confiable (no se rompe con cambios de HTML)
- ‚úÖ M√°s r√°pido (sin parsing de HTML)
- ‚úÖ Datos estructurados (marca, modelo, stock, etc.)

**Implementaci√≥n**:
```python
async def scrape_mercadolibre_api(product_url: str) -> tuple[Decimal, str]:
    # Extraer item_id de URL
    item_id = extract_ml_item_id(product_url)
    
    # Consultar API p√∫blica (sin auth)
    response = await http.get(f"https://api.mercadolibre.com/items/{item_id}")
    data = response.json()
    
    price = Decimal(str(data['price']))
    currency = data['currency_id']
    
    return price, currency
```

---

#### **3.4 Comparaci√≥n Visual de Precios**
**Objetivo**: Gr√°fico de evoluci√≥n de precios por fuente.

**Componente nuevo**: `frontend/src/components/PriceEvolutionChart.tsx`

**Funcionalidad**:
- Line chart con √∫ltimos 30 d√≠as
- Una l√≠nea por fuente
- Tooltip con detalles al hover
- Filtros por fuente y rango de fechas

**Datos**:
```typescript
interface PriceDataPoint {
  date: string;
  source_name: string;
  price: number;
}

// Endpoint nuevo:
GET /market/products/{id}/price-history?days=30
```

---

### **Nivel 4: Inteligencia Artificial** (3+ meses)

#### **4.1 Predicci√≥n de Precios**
**Modelo**: ARIMA o Prophet (Facebook)

**Features**:
- Hist√≥rico de precios (30-90 d√≠as)
- Estacionalidad (d√≠a de semana, mes)
- Eventos externos (feriados, promociones)

**Output**:
- Predicci√≥n de precio para pr√≥ximos 7 d√≠as
- Intervalo de confianza 95%
- Recomendaci√≥n: "Buen momento para comprar/vender"

---

#### **4.2 Clasificaci√≥n Autom√°tica de Fuentes Confiables**
**Objetivo**: ML para detectar fuentes con precios m√°s estables/confiables.

**Features por fuente**:
- Varianza de precios hist√≥ricos
- Frecuencia de fallos de scraping
- Tiempo de respuesta promedio
- Correlaci√≥n con otras fuentes

**Score**:
- 0-100: Confiabilidad de la fuente
- Autom√°ticamente marca fuentes con score >80 como `is_mandatory`

---

## üìù Actualizaci√≥n de Documentaci√≥n

### **Archivos a Corregir**

#### **1. README.md**
```markdown
# ANTES:
docker exec -it growen-db-1 psql ...

# DESPU√âS:
docker exec -it growen-postgres psql -U growen -d growen
```

#### **2. docs/API_MARKET.md**
- [ ] Agregar secci√≥n "C√°lculo Autom√°tico de Rango"
- [ ] Documentar que `market_price_min` y `market_price_max` se calculan desde `market_sources.last_price`
- [ ] Agregar ejemplos de respuesta con rangos calculados

#### **3. docker-compose.yml**
- [ ] Comentar nombres de contenedores:
```yaml
services:
  db:
    container_name: growen-postgres  # ‚Üê Nombre real del contenedor
    ...
  redis:
    container_name: growen-redis  # ‚Üê Nombre real del contenedor
    ...
```

#### **4. scripts/README_SCRIPTS.md** (nuevo)
- [ ] Documentar todos los scripts en `scripts/`
- [ ] Explicar cu√°ndo usar cada uno
- [ ] Listar dependencias (Docker, Redis, PostgreSQL)

---

## ‚úÖ Checklist de Implementaci√≥n

### **Fase 1: Reparaci√≥n (HOY)** üî¥
- [ ] Matar proceso worker zombie (PID 15616)
- [ ] Cambiar `REDIS_URL` a `127.0.0.1` en `.env`
- [ ] Reiniciar worker desde admin panel
- [ ] Probar actualizaci√≥n de precios en UI
- [ ] Confirmar que rango se actualiza autom√°ticamente
- [ ] Actualizar este documento con resultado

### **Fase 2: Documentaci√≥n (Esta semana)** üìù
- [ ] Corregir nombres de contenedores en README.md
- [ ] Actualizar docs/API_MARKET.md con c√°lculo de rango
- [ ] Crear docs/WORKER_TROUBLESHOOTING.md
- [ ] Agregar secci√≥n "Workers" a Roadmap.md

### **Fase 3: Mejoras (Pr√≥ximas 2 semanas)** üîß
- [ ] Implementar health check del worker
- [ ] Agregar retry logic inteligente
- [ ] Implementar cache de scraping (1 hora TTL)
- [ ] Crear endpoint `/market/products/{id}/price-history`

### **Fase 4: Evoluciones (Pr√≥ximo mes)** üöÄ
- [ ] Scraping programado con APScheduler
- [ ] Detecci√≥n de anomal√≠as de precio
- [ ] Integraci√≥n con API de Mercado Libre
- [ ] Gr√°fico de evoluci√≥n de precios en UI

---

## üìä M√©tricas de √âxito

### **Indicadores Actuales** (Manual)
- Rango de precios: ‚úÖ Se calcula correctamente
- Actualizaci√≥n de precios: ‚ùå Requiere inserci√≥n manual
- Worker de scraping: ‚ùå No funciona (sin Redis)

### **Indicadores Deseados** (Autom√°tico)
- Rango de precios: ‚úÖ Calculado autom√°ticamente
- Actualizaci√≥n de precios: ‚úÖ Autom√°tica cada 6-24h seg√∫n categor√≠a
- Worker de scraping: ‚úÖ Procesando tareas en tiempo real
- Cobertura de fuentes: >80% de productos con al menos 2 fuentes
- √âxito de scraping: >90% de fuentes retornan precio v√°lido
- Latencia promedio: <5 segundos por fuente

---

## üéØ Conclusi√≥n

### **Estado Actual**
‚úÖ **C√°lculo de rango**: Implementado y funcionando  
‚ùå **Worker de scraping**: Roto (sin conexi√≥n a Redis)  
‚ö†Ô∏è **Scraping autom√°tico**: Listo pero no se ejecuta  

### **Pr√≥ximos Pasos Inmediatos**
1. Reparar worker (cambiar localhost ‚Üí 127.0.0.1)
2. Probar actualizaci√≥n de precios end-to-end
3. Documentar nombres correctos de contenedores
4. Implementar health checks

### **Visi√≥n a Largo Plazo**
- Sistema totalmente autom√°tico de actualizaci√≥n de precios
- Predicci√≥n de precios con ML
- Alertas inteligentes de oportunidades de compra/venta
- Integraci√≥n con m√∫ltiples marketplaces (ML, OLX, etc.)

---

**√öltima actualizaci√≥n**: 2025-11-16 14:15  
**Pr√≥xima revisi√≥n**: Despu√©s de reparar worker